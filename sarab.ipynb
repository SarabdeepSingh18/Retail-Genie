{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e101231",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sarabdeepsingh/anaconda3/envs/dl/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Importing plotly failed. Interactive plots will not work.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mprophet\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Prophet\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m mean_squared_error, mean_absolute_error\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpmdarima\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m auto_arima\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[1;32m     10\u001b[0m warnings\u001b[38;5;241m.\u001b[39mfilterwarnings(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/dl/lib/python3.10/site-packages/pmdarima/__init__.py:52\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __check_build\n\u001b[1;32m     51\u001b[0m \u001b[38;5;66;03m# Stuff we want at top-level\u001b[39;00m\n\u001b[0;32m---> 52\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marima\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m auto_arima, ARIMA, AutoARIMA, StepwiseContext, decompose\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m acf, autocorr_plot, c, pacf, plot_acf, plot_pacf, \\\n\u001b[1;32m     54\u001b[0m     tsdisplay\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_show_versions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m show_versions\n",
      "File \u001b[0;32m~/anaconda3/envs/dl/lib/python3.10/site-packages/pmdarima/arima/__init__.py:5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# -*- coding: utf-8 -*-\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Author: Taylor Smith <taylor.smith@alkaline-ml.com>\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapprox\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marima\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mauto\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/dl/lib/python3.10/site-packages/pmdarima/arima/approx.py:9\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# -*- coding: utf-8 -*-\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Author: Taylor Smith <taylor.smith@alkaline-ml.com>\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# R approx function\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marray\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m c, check_endog\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_callable\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DTYPE\n",
      "File \u001b[0;32m~/anaconda3/envs/dl/lib/python3.10/site-packages/pmdarima/utils/__init__.py:5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# -*- coding: utf-8 -*-\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Author: Taylor Smith <taylor.smith@alkaline-ml.com>\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marray\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetaestimators\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvisualization\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/dl/lib/python3.10/site-packages/pmdarima/utils/array.py:13\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DTYPE\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_array\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m C_intgrt_vec\n\u001b[1;32m     15\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mas_series\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mc\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mis_iterable\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     23\u001b[0m ]\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mas_series\u001b[39m(x, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n",
      "File \u001b[0;32mpmdarima/utils/_array.pyx:1\u001b[0m, in \u001b[0;36minit pmdarima.utils._array\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "from prophet import Prophet\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from pmdarima import auto_arima\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0d54c359",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "data = pd.read_csv('retail.csv')\n",
    "data['InvoiceDate'] = pd.to_datetime(data['InvoiceDate'])\n",
    "data = data.set_index('InvoiceDate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f89e7341",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's visualize the data\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(data.index, data['Sales'])\n",
    "plt.title('Daily Sales')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Sales')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig('sales_time_series.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "57c77775",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values: Unnamed: 0    0\n",
      "Sales         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values and handle outliers\n",
    "print(\"Missing values:\", data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6e57c28e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of outliers: 21\n"
     ]
    }
   ],
   "source": [
    "# Detect and handle outliers\n",
    "Q1 = data['Sales'].quantile(0.25)\n",
    "Q3 = data['Sales'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "outliers = data[(data['Sales'] < lower_bound) | (data['Sales'] > upper_bound)]\n",
    "print(f\"Number of outliers: {len(outliers)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "66e3a96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For extreme outliers, we can cap them but still preserve the trend\n",
    "data_processed = data.copy()\n",
    "data_processed.loc[data_processed['Sales'] > upper_bound * 2, 'Sales'] = upper_bound * 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "68e250ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plot the processed data\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(data_processed.index, data_processed['Sales'])\n",
    "plt.title('Daily Sales (Processed)')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Sales')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig('sales_processed.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2abef642",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data: 2010-12-01 00:00:00 to 2011-09-25 00:00:00\n",
      "Testing data: 2011-09-26 00:00:00 to 2011-12-09 00:00:00\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Resample to weekly data to reduce noise (optional)\n",
    "weekly_data = data_processed.resample('W').mean()\n",
    "\n",
    "# Split the data: use 80% for training, 20% for testing\n",
    "train_size = int(len(data_processed) * 0.8)\n",
    "train_data = data_processed.iloc[:train_size]\n",
    "test_data = data_processed.iloc[train_size:]\n",
    "\n",
    "print(f\"Training data: {train_data.index.min()} to {train_data.index.max()}\")\n",
    "print(f\"Testing data: {test_data.index.min()} to {test_data.index.max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "93c69ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to evaluate models\n",
    "def evaluate_model(y_true, y_pred, model_name):\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "    print(f\"{model_name} - MAE: {mae:.2f}, RMSE: {rmse:.2f}, MAPE: {mape:.2f}%\")\n",
    "    return {'mae': mae, 'rmse': rmse, 'mape': mape}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6dfa6730",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing stepwise search to minimize aic\n",
      " ARIMA(0,1,0)(0,1,0)[7]             : AIC=2332.100, Time=0.01 sec\n",
      " ARIMA(1,1,0)(1,1,0)[7]             : AIC=2250.405, Time=0.06 sec\n",
      " ARIMA(0,1,1)(0,1,1)[7]             : AIC=inf, Time=0.24 sec\n",
      " ARIMA(1,1,0)(0,1,0)[7]             : AIC=2302.557, Time=0.02 sec\n",
      " ARIMA(1,1,0)(2,1,0)[7]             : AIC=2238.527, Time=0.13 sec\n",
      " ARIMA(1,1,0)(2,1,1)[7]             : AIC=inf, Time=0.36 sec\n",
      " ARIMA(1,1,0)(1,1,1)[7]             : AIC=inf, Time=0.29 sec\n",
      " ARIMA(0,1,0)(2,1,0)[7]             : AIC=2275.137, Time=0.10 sec\n",
      " ARIMA(2,1,0)(2,1,0)[7]             : AIC=2194.419, Time=0.19 sec\n",
      " ARIMA(2,1,0)(1,1,0)[7]             : AIC=2200.472, Time=0.12 sec\n",
      " ARIMA(2,1,0)(2,1,1)[7]             : AIC=inf, Time=0.83 sec\n",
      " ARIMA(2,1,0)(1,1,1)[7]             : AIC=inf, Time=0.23 sec\n",
      " ARIMA(3,1,0)(2,1,0)[7]             : AIC=2158.138, Time=0.23 sec\n",
      " ARIMA(3,1,0)(1,1,0)[7]             : AIC=2169.271, Time=0.15 sec\n",
      " ARIMA(3,1,0)(2,1,1)[7]             : AIC=inf, Time=0.84 sec\n",
      " ARIMA(3,1,0)(1,1,1)[7]             : AIC=inf, Time=0.59 sec\n",
      " ARIMA(3,1,1)(2,1,0)[7]             : AIC=inf, Time=0.94 sec\n",
      " ARIMA(2,1,1)(2,1,0)[7]             : AIC=inf, Time=0.77 sec\n",
      " ARIMA(3,1,0)(2,1,0)[7] intercept   : AIC=2160.137, Time=0.35 sec\n",
      "\n",
      "Best model:  ARIMA(3,1,0)(2,1,0)[7]          \n",
      "Total fit time: 6.473 seconds\n",
      "Best SARIMA parameters: (3, 1, 0) (2, 1, 0, 7)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 1. SARIMA Model\n",
    "# Use auto_arima to find the best parameters\n",
    "sarima_model = auto_arima(\n",
    "    train_data['Sales'],\n",
    "    seasonal=True, \n",
    "    m=7,  # Weekly seasonality\n",
    "    start_p=0, start_q=0,\n",
    "    max_p=3, max_q=3,\n",
    "    start_P=0, start_Q=0,\n",
    "    max_P=2, max_Q=2,\n",
    "    d=1, D=1,\n",
    "    trace=True,\n",
    "    error_action='ignore',\n",
    "    suppress_warnings=True,\n",
    "    stepwise=True\n",
    ")\n",
    "\n",
    "print(\"Best SARIMA parameters:\", sarima_model.order, sarima_model.seasonal_order)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9e8792a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "final_sarima = SARIMAX(\n",
    "    train_data['Sales'],\n",
    "    order=sarima_model.order,\n",
    "    seasonal_order=sarima_model.seasonal_order\n",
    ")\n",
    "sarima_fitted = final_sarima.fit(disp=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a066d8e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SARIMA - MAE: 10.16, RMSE: 14.60, MAPE: 48.92%\n"
     ]
    }
   ],
   "source": [
    "# Forecast\n",
    "sarima_forecast = sarima_fitted.forecast(steps=len(test_data))\n",
    "sarima_metrics = evaluate_model(test_data['Sales'], sarima_forecast, \"SARIMA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a35b3a0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in data: Index(['InvoiceDate', 'Unnamed: 0', 'Sales'], dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17:55:17 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:55:18 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<prophet.forecaster.Prophet at 0x1b2f5c9fd90>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. Prophet Model\n",
    "# Prepare data for Prophet\n",
    "prophet_data = data_processed.reset_index()\n",
    "# Check the actual columns in your data\n",
    "print(\"Columns in data:\", prophet_data.columns)\n",
    "\n",
    "# If there are 3 columns, we need to select just the 2 we need\n",
    "# Assuming the first column is the index/date and one of the others is 'Sales'\n",
    "prophet_data = prophet_data[['InvoiceDate', 'Sales']]\n",
    "prophet_data.columns = ['ds', 'y']\n",
    "\n",
    "# Fit Prophet model\n",
    "prophet_model = Prophet(\n",
    "    yearly_seasonality=True,\n",
    "    weekly_seasonality=True,\n",
    "    daily_seasonality=False,\n",
    "    changepoint_prior_scale=0.05\n",
    ")\n",
    "prophet_model.fit(prophet_data.iloc[:train_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fc7d8880",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Forecast\n",
    "future = prophet_model.make_future_dataframe(periods=len(test_data), freq='D')\n",
    "prophet_forecast = prophet_model.predict(future)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a78afe11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prophet - MAE: 6.30, RMSE: 9.49, MAPE: 30.03%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on test data\n",
    "prophet_pred = prophet_forecast.iloc[train_size:]['yhat'].values\n",
    "prophet_metrics = evaluate_model(test_data['Sales'].values, prophet_pred, \"Prophet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3116d61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Prophet components\n",
    "prophet_fig = prophet_model.plot_components(prophet_forecast)\n",
    "plt.savefig('prophet_components.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8ec96058",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Exponential Smoothing (ETS)\n",
    "ets_model = ExponentialSmoothing(\n",
    "    train_data['Sales'],\n",
    "    seasonal='add',\n",
    "    seasonal_periods=7,  # Weekly seasonality\n",
    "    trend='add'\n",
    ")\n",
    "ets_fitted = ets_model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "40134f84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ETS - MAE: 6.08, RMSE: 8.54, MAPE: 32.32%\n"
     ]
    }
   ],
   "source": [
    "# Forecast\n",
    "ets_forecast = ets_fitted.forecast(steps=len(test_data))\n",
    "ets_metrics = evaluate_model(test_data['Sales'], ets_forecast, \"ETS\")\n",
    "\n",
    "# Compare models and select the best one\n",
    "models = {\n",
    "    'SARIMA': {'metrics': sarima_metrics, 'forecast': sarima_forecast},\n",
    "    'Prophet': {'metrics': prophet_metrics, 'forecast': prophet_pred},\n",
    "    'ETS': {'metrics': ets_metrics, 'forecast': ets_forecast}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "26781676",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best model based on RMSE: ETS\n"
     ]
    }
   ],
   "source": [
    "# Find the best model based on RMSE\n",
    "best_model = min(models.items(), key=lambda x: x[1]['metrics']['rmse'])[0]\n",
    "print(f\"\\nBest model based on RMSE: {best_model}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fe664a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot actual vs. forecasted values for the best model\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(data_processed.index, data_processed['Sales'], label='Actual')\n",
    "plt.plot(test_data.index, models[best_model]['forecast'], 'r--', label=f'{best_model} Forecast')\n",
    "plt.axvline(x=train_data.index[-1], color='k', linestyle='--')\n",
    "plt.title(f'Sales Forecast using {best_model}')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Sales')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig('best_model_forecast.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "31388983",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now forecast future sales (next 30 days)\n",
    "if best_model == 'SARIMA':\n",
    "    future_model = SARIMAX(\n",
    "        data_processed['Sales'],\n",
    "        order=sarima_model.order,\n",
    "        seasonal_order=sarima_model.seasonal_order\n",
    "    )\n",
    "    future_fitted = future_model.fit(disp=False)\n",
    "    future_forecast = future_fitted.forecast(steps=30)\n",
    "    future_index = pd.date_range(start=data_processed.index[-1] + pd.Timedelta(days=1), periods=30, freq='D')\n",
    "    \n",
    "elif best_model == 'Prophet':\n",
    "    future = prophet_model.make_future_dataframe(periods=len(test_data) + 30, freq='D')\n",
    "    prophet_future = prophet_model.predict(future)\n",
    "    future_forecast = prophet_future.iloc[-30:]['yhat'].values\n",
    "    future_index = pd.date_range(start=data_processed.index[-1] + pd.Timedelta(days=1), periods=30, freq='D')\n",
    "    \n",
    "else:  # ETS\n",
    "    ets_full_model = ExponentialSmoothing(\n",
    "        data_processed['Sales'],\n",
    "        seasonal='add',\n",
    "        seasonal_periods=7,\n",
    "        trend='add'\n",
    "    )\n",
    "    ets_full_fitted = ets_full_model.fit()\n",
    "    future_forecast = ets_full_fitted.forecast(steps=30)\n",
    "    future_index = pd.date_range(start=data_processed.index[-1] + pd.Timedelta(days=1), periods=30, freq='D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2c4c776e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Future Sales Forecast (Next 30 days):\n",
      "                 Date  Forecasted_Sales\n",
      "2011-12-10 2011-12-10         18.053176\n",
      "2011-12-11 2011-12-11         12.141784\n",
      "2011-12-12 2011-12-12         20.308052\n",
      "2011-12-13 2011-12-13         25.749542\n",
      "2011-12-14 2011-12-14         22.132610\n",
      "2011-12-15 2011-12-15         24.117335\n",
      "2011-12-16 2011-12-16         24.505457\n",
      "2011-12-17 2011-12-17         18.024358\n",
      "2011-12-18 2011-12-18         12.112966\n",
      "2011-12-19 2011-12-19         20.279234\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create a dataframe with future predictions\n",
    "future_df = pd.DataFrame({\n",
    "    'Date': future_index,\n",
    "    'Forecasted_Sales': future_forecast\n",
    "})\n",
    "\n",
    "print(\"\\nFuture Sales Forecast (Next 30 days):\")\n",
    "print(future_df.head(10))\n",
    "\n",
    "# Plot the historical data and future forecast\n",
    "plt.figure(figsize=(15, 7))\n",
    "plt.plot(data_processed.index, data_processed['Sales'], label='Historical Sales')\n",
    "plt.plot(future_index, future_forecast, 'r--', label='Future Forecast')\n",
    "plt.title(f'Sales Forecast for Next 30 Days using {best_model}')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Sales')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig('future_forecast.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7b5d553b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance analysis (for Prophet)\n",
    "if best_model == 'Prophet':\n",
    "    # Extract the components and their contribution\n",
    "    components = prophet_forecast[['trend', 'weekly', 'yearly']]\n",
    "    \n",
    "    # Calculate the magnitude of each component\n",
    "    component_influence = {\n",
    "        'Trend': components['trend'].max() - components['trend'].min(),\n",
    "        'Weekly Seasonality': components['weekly'].max() - components['weekly'].min(),\n",
    "        'Yearly Seasonality': components['yearly'].max() - components['yearly'].min()\n",
    "    }\n",
    "    \n",
    "    print(\"\\nComponent Influence in Sales Patterns:\")\n",
    "    for component, influence in component_influence.items():\n",
    "        print(f\"{component}: {influence:.2f}\")\n",
    "    \n",
    "    # Plot the components\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.subplot(3, 1, 1)\n",
    "    plt.plot(prophet_forecast['ds'], prophet_forecast['trend'])\n",
    "    plt.title('Trend Component')\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.subplot(3, 1, 2)\n",
    "    plt.plot(prophet_forecast['ds'], prophet_forecast['weekly'])\n",
    "    plt.title('Weekly Seasonality Component')\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.subplot(3, 1, 3)\n",
    "    plt.plot(prophet_forecast['ds'], prophet_forecast['yearly'])\n",
    "    plt.title('Yearly Seasonality Component')\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('component_analysis.png')\n",
    "    plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "988bc975",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ETS model and future forecasts saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# Save the model and forecasts\n",
    "import pickle\n",
    "\n",
    "if best_model == 'SARIMA':\n",
    "    model_to_save = sarima_fitted\n",
    "elif best_model == 'Prophet':\n",
    "    model_to_save = prophet_model\n",
    "else:\n",
    "    model_to_save = ets_full_fitted\n",
    "\n",
    "# Save the final model\n",
    "with open(f'{best_model}_model.pkl', 'wb') as f:\n",
    "    pickle.dump(model_to_save, f)\n",
    "\n",
    "# Save the future forecasts\n",
    "future_df.to_csv('future_sales_forecast.csv', index=False)\n",
    "\n",
    "print(f\"\\n{best_model} model and future forecasts saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52410030",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
